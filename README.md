# AudioGuide (Powered by Gen-AI)

## What and why?

People don't go to museums because they don't know what to look at. Traditional museum experiences often leave visitors overwhelmed or missing important context, while human guides are limited in availability and costly. We want to design a mobile application that serves as a personalized museum tour guide using Large Language Models.

## For whom?

Let's start with the Greek & Roman Gallery at the Metropolitan Museum of Art, so the primary users will be visitors at the gallery. Our users might have different art history backgrounds, and could include children, students, the elderly, and others.

## How?

Users will download the app, set their preferences (interests, time available, and accessibility needs), and put in the number of the exhibits. The app will provide real-time information, answer questions about the artwork through natural language processing, and suggest personalized routes through the museum.

## Scope

For a team of 4-6 programmers over one semester, we will focus on developing the core mobile app with tour generation and Q&A capabilities for an initial database of 50 key artworks. We also need to arrange the databast by ourselves.